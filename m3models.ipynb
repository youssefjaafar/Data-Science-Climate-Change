{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"m3models.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"25svZFzhDpb9"},"source":["### Neural Network Model"]},{"cell_type":"markdown","metadata":{"id":"_UsEuUDOPR05"},"source":["#### Build an ANN model"]},{"cell_type":"code","metadata":{"id":"2jIKArSg2W0f"},"source":["import math\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import Model\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.layers import Dense, Dropout\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.losses import MeanSquaredLogarithmicError"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RexoDc8kEL_K","colab":{"base_uri":"https://localhost:8080/","height":438},"executionInfo":{"status":"error","timestamp":1638443319871,"user_tz":-120,"elapsed":715,"user":{"displayName":"Youssef Jaafar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiD44OP8sBVCl8xLaOgdwIZq38wxhK6X1Lk6H9vsA=s64","userId":"18068023583815590687"}},"outputId":"aefbb087-de1d-421b-a03e-151dcf9d2bb8"},"source":["TRAIN_DATA_PATH = '/content/sample_data/california_housing_train.csv'\n","TEST_DATA_PATH = '/content/sample_data/california_housing_test.csv'\n","TARGET_NAME = 'median_house_value'\n","\n","df= pd.read_csv(\"\")\n","\n","#x values from dataframe, FEATURES\n","X= df.iloc[:, :]\n","\n","#y values from dataframe, TARGET\n","y= df.iloc[:, :]"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-10c237ffde62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTARGET_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'median_house_value'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#x values from dataframe, FEATURES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"]}]},{"cell_type":"code","metadata":{"id":"DRbkfMX1yX9z"},"source":["print(X.shape())\n","print(y.shape())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nD-URBC7yW7t"},"source":["x_train, x_test, y_train, y_test= train_test_split(X, y, test_size=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5UcmHBC4yZ1U"},"source":["print(x_train.shape())\n","print(x_test.shape())\n","print(y_train.shape())\n","print(y_test.shape())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mTD68PNUD0ED"},"source":["\"\"\"\n","  Standard Scale test and train data\n","  Z - Score normalization\n","  \"\"\"\n","\n","  def scale_datasets():\n","    standard_scaler = StandardScaler()\n","\n","    x_train_scaled = pd.DataFrame(\n","      standard_scaler.fit_transform(x_train),\n","      columns=x_train.columns\n","    )\n","\n","    x_test_scaled = pd.DataFrame(\n","      standard_scaler.transform(x_test),\n","      columns = x_test.columns\n","    )\n","\n","  return x_train_scaled, x_test_scaled\n","  \n","x_train_scaled, x_test_scaled = scale_datasets(x_train, x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x-CB5dtqD3gt"},"source":["hidden_units1 = 160 #CAN CHANGE THEM, hyperparam search\n","hidden_units2 = 480\n","hidden_units3 = 256\n","learning_rate = 0.01\n","\n","in_shape= # = to the number of input columns \n","\n","# Creating model using the Sequential in tensorflow\n","\n","#DO WE USE FLATTEN??\n","\n","def build_model():\n","  model = Sequential([\n","    Dense(hidden_units1, input_shape= (in_shape,), kernel_initializer='normal', activation='relu'),\n","    Dropout(0.2),\n","    Dense(hidden_units2, kernel_initializer='normal', activation='relu'),\n","    Dropout(0.2),\n","    Dense(hidden_units3, kernel_initializer='normal', activation='relu'),\n","    Dense(1, kernel_initializer='normal', activation='linear') #linear activation for regression \n","  ])\n","  return model\n","\n","#OR \n","model=Sequential()\n","model.add(Dense(hidden_units1, input_shape= (in_shape,), activation='sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T1QJj3SCAuVG"},"source":["# build the model\n","model = build_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nneJ5LXaD6ED"},"source":["# loss function\n","msle = MeanSquaredLogarithmicError()\n","\n","#sgd= SGD(lr=0.01) or ADAM\n","#TRY BOTH\n","\n","model.compile(\n","    loss=msle, #loss= 'mean_squared_error'\n","    optimizer=Adam(learning_rate=learning_rate), #optimizer= sgd,\n","    metrics=[msle]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tDfU2PJO0u38"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zmN6n5Ra0wTf"},"source":["# train the model\n","history = model.fit(\n","    x_train_scaled.values, \n","    y_train.values, \n","    epochs=10, #10, 20, 100 ... ?\n","    batch_size=64, #32, 64, 128\n","    validation_split=0.2,\n","    verbose=1\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e1em-mQKD8l9"},"source":["def plot_history(history, key):\n","  plt.plot(history.history[key])\n","  plt.plot(history.history['val_'+key])\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(key)\n","  plt.legend([key, 'val_'+key])\n","  plt.show()\n","# Plot the history\n","plot_history(history, 'mean_squared_logarithmic_error')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e1HhmVAg1soL"},"source":["# evaluate the model\n","y_pred= model.predict(x_test_scaled)\n","print('R^2: {:.5f}'.format(r2_score(ytest, ypred)))\n","print('RMSE: {:.5f}'.format(np.sqrt(mean_squared_error(ytest, ypred))))\n","print('MSE: {:.5f}'.format(mean_squared_error(ytest, ypred)))\n","print('MAE: {:.5f}'.format(mean_absolute_error(ytest, ypred)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kP1XF2nnD_YO"},"source":["# add the predictions to the dataframe\n","# x_test['prediction'] = model.predict(x_test_scaled)\n","x_test['prediction'] = y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tuL4rAHKPMyd"},"source":["#### Build an RNN model"]},{"cell_type":"code","metadata":{"id":"BBGL4ah7_qF1"},"source":["#define the model\n","\n","def build_rnn_model():\n","  model = Sequential([\n","  #LSTM layer \n","  LSTM(64, return_sequences=False, dropout=0.1, recurrent_dropout=0.1)\n","  # Fully connected layer\n","  Dense(64, activation='relu')\n","  # Dropout for regularization\n","  Dropout(0.5)\n","  # Output layer\n","  Dense(1, activation='linear')\n","  ])\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHMmwKhRAzed"},"source":["# build the model\n","rnn_model = build_rnn_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SZPLZM2ZDJLi"},"source":["# loss function\n","msle = MeanSquaredLogarithmicError()\n","\n","#sgd= SGD(lr=0.01) or ADAM\n","#TRY BOTH\n","\n","rnn_model.compile(\n","    loss=msle, #loss= 'mean_squared_error'\n","    optimizer=Adam(learning_rate=learning_rate), #optimizer= sgd,\n","    metrics=[msle]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9GRdTUn6DPvj"},"source":["rnn_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1uFV_VADDSER"},"source":["# train the model\n","history_rnn = rnn_model.fit(\n","    x_train_scaled.values, \n","    y_train.values, \n","    epochs=10, #10, 20, 100 ... ?\n","    batch_size=64, #32, 64, 128\n","    validation_split=0.2,\n","    verbose=1\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lBKiSkTDDhdl"},"source":["plot_history(history_rnn, 'mean_squared_logarithmic_error')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8a_5Uot5DZwG"},"source":["# evaluate the model\n","y_pred= rnn_model.predict(x_test_scaled)\n","print('R^2: {:.5f}'.format(r2_score(ytest, ypred)))\n","print('RMSE: {:.5f}'.format(np.sqrt(mean_squared_error(ytest, ypred))))\n","print('MSE: {:.5f}'.format(mean_squared_error(ytest, ypred)))\n","print('MAE: {:.5f}'.format(mean_absolute_error(ytest, ypred)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cw-yWjHiOkx5"},"source":["#### Define a model with hyperparameter tuning "]},{"cell_type":"code","metadata":{"id":"h5d8KoeVOorU"},"source":["def model_builder(hp):\n","  model = Sequential()\n","\n","  # Tune the number of units in the first Dense layer\n","  # Choose an optimal value between 32-512\n","  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n","  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n","\n","  model.add(keras.layers.Dense(10))\n","\n","  # Tune the learning rate for the optimizer\n","  # Choose an optimal value from 0.01, 0.001, or 0.0001\n","  hp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3, 1e-4])\n","\n","  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n","                loss='mean_squared_error',\n","                metrics=['accuracy'])\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dc9R5KyYOqI9"},"source":["# instantiate the tuner and perform hypertuning \n","\n","tuner = kt.Hyperband(model_builder,\n","                     objective='val_accuracy',\n","                     max_epochs=10,\n","                     #factor=3,\n","                     )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ylg4DOCOOwk1"},"source":["#Create a callback to stop training early after reaching a certain value for the validation loss\n","\n","stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FJWXr-BoO1pH"},"source":["# run the search \n","tuner.search(x_train_scaled, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n","\n","# Get the optimal hyperparameters\n","best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n","\n","print(f\"\"\"\n","The hyperparameter search is complete. The optimal number of units in the first densely-connected\n","layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n","is {best_hps.get('learning_rate')}.\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-c7Y9zFmO45M"},"source":["# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n","\n","model = tuner.hypermodel.build(best_hps)\n","history = model.fit(img_train, label_train, epochs=50, validation_split=0.2)\n","\n","val_acc_per_epoch = history.history['val_accuracy']\n","best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n","print('Best epoch: %d' % (best_epoch,))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ZUKawfSO_4Q"},"source":["hypermodel = tuner.hypermodel.build(best_hps)\n","\n","# Retrain the model\n","\n","hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xO_5A50qPCYk"},"source":["eval_result = hypermodel.evaluate(img_test, label_test)\n","print(\"[test loss, test accuracy]:\", eval_result)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4dy5DIrlEH8R"},"source":["https://www.analyticsvidhya.com/blog/2021/08/a-walk-through-of-regression-analysis-using-artificial-neural-networks-in-tensorflow/"]},{"cell_type":"markdown","metadata":{"id":"NWBoUpiMPDA1"},"source":["https://www.tensorflow.org/tutorials/keras/keras_tuner"]},{"cell_type":"markdown","metadata":{"id":"P3jzzRkkiAvY"},"source":["### SVM "]},{"cell_type":"markdown","metadata":{"id":"Lm7bNHTSQx6m"},"source":["#### A Basic SVR for regression"]},{"cell_type":"code","metadata":{"id":"Q-YswCj6iCsE"},"source":["df = pd.read_csv('')\n","X = df.iloc[:, 1:2].values\n","y = df.iloc[:, 2].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VkJoW2YYie7D"},"source":["from sklearn.preprocessing import StandardScaler\n","\n","sc_X = StandardScaler()\n","sc_y = StandardScaler()\n","X = sc_X.fit_transform(X)\n","y = sc_y.fit_transform(y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HiO3MSy0ivd8"},"source":["from sklearn.svm import SVR\n","\n","regressor = SVR(kernel = 'linear')\n","regressor.fit(X, y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IRCb46vci04P"},"source":["y_pred = regressor.predict(6.5)\n","y_pred = sc_y.inverse_transform(y_pred) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lsFohRSUjF1I"},"source":["X_grid = np.arange(min(X), max(X), 0.01) #this step required because data is feature scaled.\n","X_grid = X_grid.reshape((len(X_grid), 1))\n","plt.scatter(X, y, color = 'red')\n","plt.plot(X_grid, regressor.predict(X_grid), color = 'blue')\n","plt.title('')\n","plt.xlabel('')\n","plt.ylabel('')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n8lqTKCOjOV6"},"source":["https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/\n"]},{"cell_type":"markdown","metadata":{"id":"e-tYU2VNQ1VQ"},"source":["#### SVR Using Cross Validation and Hyperparameter Tuning"]},{"cell_type":"code","metadata":{"id":"gCfLW3o8Q0vG"},"source":["import math\n","import itertools\n","import optunity\n","import optunity.metrics\n","import sklearn.svm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fBlHJrBe6FOX"},"source":["# explicitly generate the outer_cv decorator so we can use it more than once\n","\n","outer_cv = optunity.cross_validated(x=x_train, y=y_train, num_folds=10) #10-fold cros validation\n","\n","def compute_mse_standard(x_train, y_train, x_test, y_test):\n","    \"\"\"Computes MSE of an SVR with RBF kernel and default hyperparameters.\n","    \"\"\"\n","    model = sklearn.svm.SVR().fit(x_train, y_train)\n","    predictions = model.predict(x_test)\n","    return optunity.metrics.mse(y_test, predictions)\n","\n","# wrap with outer cross-validation\n","compute_mse_standard = outer_cv(compute_mse_standard) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ax9xAesCRQvK"},"source":["compute_mse_standard() # returns a three-fold cross-validation estimate of MSE for an SVR with default hyperparameters."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"myL377iXRe73"},"source":["# function that returns MSE based on optimized hyperparameters, where we choose a polynomial kernel in advance.\n","\n","def compute_mse_poly_tuned(x_train, y_train, x_test, y_test):\n","    \"\"\"Computes MSE of an SVR with RBF kernel and optimized hyperparameters.\"\"\"\n","\n","    # define objective function for tuning\n","    @optunity.cross_validated(x=x_train, y=y_train, num_iter=2, num_folds=5)\n","    def tune_cv(x_train, y_train, x_test, y_test, C, degree, coef0):\n","        model = sklearn.svm.SVR(C=C, degree=degree, coef0=coef0, kernel='poly').fit(x_train, y_train)\n","        predictions = model.predict(x_test)\n","        return optunity.metrics.mse(y_test, predictions)\n","\n","    # optimize parameters\n","    optimal_pars, _, _ = optunity.minimize(tune_cv, 150, C=[1000, 20000], degree=[2, 5], coef0=[0, 1])\n","    print(\"optimal hyperparameters: \" + str(optimal_pars))\n","\n","    tuned_model = sklearn.svm.SVR(kernel='poly', **optimal_pars).fit(x_train, y_train)\n","    predictions = tuned_model.predict(x_test)\n","    return optunity.metrics.mse(y_test, predictions)\n","\n","# wrap with outer cross-validation\n","compute_mse_poly_tuned = outer_cv(compute_mse_poly_tuned)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2lXnB1pRncn"},"source":["compute_mse_poly_tuned()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NXZtSQQsRrgk"},"source":["# using an RBF kernel \n","\n","def compute_mse_rbf_tuned(x_train, y_train, x_test, y_test):\n","    \"\"\"Computes MSE of an SVR with RBF kernel and optimized hyperparameters.\"\"\"\n","\n","    # define objective function for tuning\n","    @optunity.cross_validated(x=x_train, y=y_train, num_iter=2, num_folds=5)\n","    def tune_cv(x_train, y_train, x_test, y_test, C, gamma):\n","        model = sklearn.svm.SVR(C=C, gamma=gamma).fit(x_train, y_train)\n","        predictions = model.predict(x_test)\n","        return optunity.metrics.mse(y_test, predictions)\n","\n","    # optimize parameters\n","    optimal_pars, _, _ = optunity.minimize(tune_cv, 150, C=[1, 100], gamma=[0, 50])\n","    print(\"optimal hyperparameters: \" + str(optimal_pars))\n","\n","    tuned_model = sklearn.svm.SVR(**optimal_pars).fit(x_train, y_train)\n","    predictions = tuned_model.predict(x_test)\n","    return optunity.metrics.mse(y_test, predictions)\n","\n","# wrap with outer cross-validation\n","compute_mse_rbf_tuned = outer_cv(compute_mse_rbf_tuned)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"unNQn0xIR8I6"},"source":["compute_mse_rbf_tuned()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5_TdDOQKSIri"},"source":["We can do all prevoious tests using optunity:\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"PshOXb_kR-ol"},"source":["# we define the search space (we will try the linear, polynomial and RBF kernel).\n","\n","space = {'kernel': {'linear': {'C': [0, 100]},\n","                    'rbf': {'gamma': [0, 50], 'C': [1, 100]},\n","                    'poly': {'degree': [2, 5], 'C': [1000, 20000], 'coef0': [0, 1]}\n","                    }\n","         }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BsOyoEyFSNSi"},"source":["# we perform nested cross validation \n","\n","def compute_mse_all_tuned(x_train, y_train, x_test, y_test):\n","    \"\"\"Computes MSE of an SVR with RBF kernel and optimized hyperparameters.\"\"\"\n","\n","    # define objective function for tuning\n","    @optunity.cross_validated(x=x_train, y=y_train, num_iter=2, num_folds=5)\n","    def tune_cv(x_train, y_train, x_test, y_test, kernel, C, gamma, degree, coef0):\n","        if kernel == 'linear':\n","            model = sklearn.svm.SVR(kernel=kernel, C=C)\n","        elif kernel == 'poly':\n","            model = sklearn.svm.SVR(kernel=kernel, C=C, degree=degree, coef0=coef0)\n","        elif kernel == 'rbf':\n","            model = sklearn.svm.SVR(kernel=kernel, C=C, gamma=gamma)\n","        else:\n","            raise ArgumentError(\"Unknown kernel function: %s\" % kernel)\n","        model.fit(x_train, y_train)\n","\n","        predictions = model.predict(x_test)\n","        return optunity.metrics.mse(y_test, predictions)\n","\n","    # optimize parameters\n","    optimal_pars, _, _ = optunity.minimize_structured(tune_cv, num_evals=150, search_space=space)\n","\n","    # remove hyperparameters with None value from optimal pars\n","    for k, v in optimal_pars.items():\n","        if v is None: del optimal_pars[k]\n","    print(\"optimal hyperparameters: \" + str(optimal_pars))\n","\n","    tuned_model = sklearn.svm.SVR(**optimal_pars).fit(x_train, y_train)\n","    predictions = tuned_model.predict(x_test)\n","    return optunity.metrics.mse(y_test, predictions)\n","\n","# wrap with outer cross-validation\n","compute_mse_all_tuned = outer_cv(compute_mse_all_tuned)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8B3MPM6GSfdg"},"source":["compute_mse_all_tuned() #get the optimal hyperparameter sets as outputs "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QUy3OfMISwpD"},"source":["https://optunity.readthedocs.io/en/latest/notebooks/notebooks/sklearn-svr.html"]}]}